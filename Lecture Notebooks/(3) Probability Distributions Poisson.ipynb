{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "\n",
    "## <font color='maroon'>ASTR 20500</font>\n",
    "\n",
    "## <font color='maroon'>Binomial and Poisson probability distributions\n",
    "   \n",
    " </center>\n",
    "<p><p>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### <font color='darkblue'>Introduction\n",
    "    \n",
    "This notebook introduces the central concepts of **_probability distribution_** and **_random variable_** using example of the binomial probability distribution. \n",
    "        \n",
    "It then motivates a different mathematical form of the binomial distribution arising in the limit $N\\rightarrow\\infty$, $p\\rightarrow 0$, but $\\lambda=Np={\\rm const}$ called **_the Poisson probability distribution_** for which expectation value and variance are equal to $\\lambda$. It ends with an illustration for how the expectation and variance of the Poisson distribution are used in the estimates of \"signal-to-noise ratio (SNR)\" of astronomical objects. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color='darkblue'>The *binomial probability distribution*\n",
    "\n",
    "The probability of  $n$ independent outcomes in $N$ trials, each having probability to occur in on trial given by $p$, is  \n",
    "\n",
    "$$p_N(n) = \\frac{N!}{n!\\,(N-n)!}\\, p^n\\,(1-p)^{N-n},$$\n",
    "\n",
    "    \n",
    "$p_N(n)$ is called the **_binomial probability distribution_**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$p_N(n)$ is called **_distribution_** because it describes how the total probability of all possible outcomes (=1) is partitioned (*distributed*) among outcomes with different number of successes $n$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**_Note:_** The binomial distribution name is because \n",
    "\n",
    "$$\\binom{N}{n} = \\frac{N!}{n!\\,(N-n)!}$$\n",
    "\n",
    "\n",
    "is called  the *binomial coefficient*. This coefficient arises in the *binomial expansion* (*bi* since there are two variables $a$ and $b$ in the expansion):\n",
    "\n",
    "$$(a+b)^N = \\binom{N}{0}a^N + \\binom{N}{1}a^{N-1}b+\\ldots +  \\binom{N}{N-1}ab^{N-1} + \\binom{N}{N}b^N = \\sum\\limits_{n=0}^N\\binom{N}{n}\\,a^{N-n}b^n.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The binomial expansion can be used to show the following. Suppose $a=p$ and $b=1-p$, then the above equation gives\n",
    "\n",
    "$$[p + (1-p)]^N = 1^N = 1 = \\sum\\limits_{n=0}^N\\binom{N}{n}\\,p^{N-n}(1-p)^n = \\sum\\limits_{n=0}^N p_N(n),$$\n",
    "\n",
    "or the sum of probabilities of all possible outcomes is 1. \n",
    "\n",
    "$$\\sum\\limits_{n=0}^N p_N(n) = 1.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**_Note_**: this is not surprising because this is what the second probability axiom postulates and binomial probability distribution was derived from these axioms. Nevertheless, this is a good check that the derived form of the distribution conforms to the 1st and 2nd axioms. This is a fundamental property of *all* probability distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### <font color='darkblue'>Random variables</font> \n",
    "\n",
    "Binomial probability distribution describes probability of $n$ outcomes we are interested in $N$ trials (or experiments), when probability of such outcome in each trial is constant value $p$. \n",
    "\n",
    "Mathematically, we can assign a variable $x_i$ to the outcome of a given trial number $i$: for example, if we are interested in the probability for 4 rainy days out of 7, we can denote $x_i=1$ if rains on day $i$ and $x_i=0$ if it does not rain. \n",
    "\n",
    "In each realization of these trials, we cannot predict with certainty whether $x_i$ will 1 or 0. We can only assign a probability of 1 or 0. Variables such as $x$ here are called **_random variables_** in probability theory and statistics. In this case, $x$ can only have two discrete valeues, $0$ and $1$, and such variables are called **_discrete random variables_**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**_A note on terminology_**: Probability distribution describing probabilistic behavior of such random variables  is called their **_parent probability distribution_** and when trials are realized, values of random variables are said to be **_drawn from the parent distribution_**. \n",
    "\n",
    "**Example**: for the cases we considered when the $x_i=1$ or $0$ with corresponding probabilities $p$ and $1-p$, the parent probability distribution is called the Bernoulli distribution:\n",
    "\n",
    "$$p_{\\rm Bernoulli}=\\begin{cases}p,\\ \\ \\ \\ \\ {\\rm for}\\ x_i=1,\\\\\n",
    "1-p, \\ {\\rm for}\\ x_i=0,\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "it is an example of a **_discrete probability distribution_** because it only has discrete values of probability for discrete values of $x$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### <font color='darkblue'>Limitations of binomial distributions:</font> \n",
    "\n",
    "Binomial distribution is great. Its derivation is intuitive and it can be usefully applied in many situations. Its use, however, has limits. \n",
    "\n",
    "Consider the case of photons from some region of the sky that pass through a telescope and imaging camera to be finally collected with a [CCD](http://spiff.rit.edu/classes/phys445/lectures/ccd1/ccd1.html) that has $5000\\times 5000$ pixels. If the sky region has no sources we will just get \"background sky\" photons scattered by the atmosphere and light of unresolved distant sources approximately uniformly distributed on the sky. Assuming photons come uniformly from all directions and hit each pixel at a certain rate.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Example_**:  This animation shows images of a region on the sky showing a detected moving asteroid (that is thought to potentially pass close to the Earth in the future). Images are taken at regular intervals in time and show sources (bright clumps), but with most pixels in between showing noise changing from image to image because it is due to random photons from the \"sky background\". It is the statistical properties of this noise that we are interested in.   \n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<img width=600 src=\"https://www.klet.org/obrazky/1999an10.gif\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Suppose photons come at a rate small enough so that during the time we expose the CCD to the sky, no more than one photon hits each pixel - that is pixels have either 0 or 1 photons. \n",
    "\n",
    "Although here we deal with a seemingly different situation (photons coming in more or less continuously and hitting different pixels), which appears different from doing $N$ trials and recording $n$ outcomes of interest, in fact it is very similar. \n",
    "\n",
    "After exposure is done with have $N=5000\\times 5000$ pixels with 0's and 1s and we can interpret $N$ pixels as $N$ trials and pixels with photons recorded (1s) as successful outcomes. So probability distribution of the number of photons $n$ (the number of successful outcomes) recorded by the CCD in this this case is still given by the binomial distribution $p_N(n)$.  \n",
    "\n",
    "However, here both the number of pixels $N$ and the number of photons $n$ can be extremely large so as to render probability calculation impossible. \n",
    "\n",
    "For example, suppose probability of photons to hit a pixel is $p=0.001$. Then $n=pN=0.001\\times 25000000=25000$. \n",
    "It's impossible to compute probability for even one configuration of $n$ pixels out of $N$ due to **_underflow_** caused by the limited number of bits used to represent floating point numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.001\n",
    "\n",
    "p**25000*(1-p)**25000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Computing factorial of 25000 is not a problem, but factorial of 25000000 will take a huge amount of time and is not practical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**_Another example and another way to think about photons collected by a CCD_**: consider a pixel or several source pixels receiving photons from a source. Photons arrive at discrete times and if we define time intervals $\\delta t$ of length so small that only 1 or 0 photons arrive in one such interval, the entire exposure time $\\tau$ during which we collect photons will consist of $N=\\tau/\\delta t$ such intervals. \n",
    "\n",
    "The $\\delta t$ time intervals are equivalent to \"trials\" during which we determine whether photon arrived or not. \n",
    "The probability to receive $n$ photons during the exposure time in these pixels will thus be described by the binomial distribution $p_N(n) = N!/n!/(N-n)!\\, p^n(1-p)^{N-n}$, where $p$ is the probability of photon arrival during $\\delta t$ which is determined by the average rate at which photons arive per unit time $r$: $p=r\\delta t$. \n",
    "\n",
    "Here again $n$ and $N$ can be very large. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This illustrates that even though binomial distribution is applicable in this situation, actually using it is not practical. Instead, its extension for this regime - **_the Poisson probability distribution_** - is used in such situations instead.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color='darkblue'>Binomial distribution in the \"large $N$, small $p$\" limit:</font> \n",
    "\n",
    "We saw that the expectation value of the binomial distribution is $Np$, let's denote this value by $\\lambda=Np$, which means that $p=\\lambda/N$. \n",
    "\n",
    "The binomial distribution can then be written as \n",
    "\n",
    "$$p_N(n) = \\frac{N!}{n!\\,(N-n)!}\\, \\left(\\lambda\\over N\\right)^n\\,\\left(1-{\\lambda\\over N}\\right)^{N-n},$$\n",
    "\n",
    "or \n",
    "\n",
    "$$p_N(n) = \\frac{\\lambda^n}{n!}\\,\\frac{N!}{(N-n)!}\\,{1\\over N^n}\\,\\left(1-{\\lambda\\over N}\\right)^{N}\\,\\left(1-{\\lambda\\over N}\\right)^{-n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we consider the limit $N\\rightarrow\\infty$, and assume that $\\lambda=Np$ stays constant (i.e. $p$ decreases as $N$ increases, in such limit $\\lambda/N\\rightarrow 0$ and \n",
    "\n",
    "$$\\frac{N!}{(N-n)!}\\,{1\\over N^n}=\\frac{N!}{N!}\\,\\frac{N(N-1)\\ldots (N-n-1)}{N^n}=1(1-1/N)(1-2/N)\\ldots (1-n/N-1/N)\\rightarrow 1.$$ \n",
    "\n",
    "$$\\left(1-{\\lambda\\over N}\\right)^{-n}\\rightarrow 1$$\n",
    "\n",
    "$$\\left(1 - {\\lambda\\over N}\\right)^N\\rightarrow e^{-\\lambda}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The latter limit is demonstrated in the Appendix B of [David Morin's book](http://www.people.fas.harvard.edu/~djmorin/probability.pdf) (see pages 113-117). A similar derivation is also presented in Section 3.5.5 of that book. No worries if you don't follow all of the details. The main thing is to understand the gist of what we are doing - computing a limiting behavior of the binomial probability distribution in the regime of very large $N$. \n",
    "\n",
    "We can also check experimentally that is is true. Try the following for different $N$ ($\\lambda=1$ here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7182831876793716"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000000\n",
    "1/(1-1/N)**N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "we can see that as $N$ is increased $1/(1-1/N)^N$ converges to the [Euler's number $e$](https://en.wikipedia.org/wiki/Euler_numbers), which means that $(1-1/N)^N$ converges to $e^{-1}$ in this case of $\\lambda=1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Optional:** For those familiar with expansions, the limit of $(1-x/N)^N$ with $N\\rightarrow\\infty$ can be found by taking natural log of the expression and expanding to first order:\n",
    "\n",
    "$$\\ln(1-x/N)^N = N\\ln(1-x/N) \\rightarrow N(-x/N + \\mathcal{O}[(x/N)^2])\\rightarrow -x,$$\n",
    "\n",
    "and so if $\\ln(1-x/N)^N$ tends to $-x$ in this limit, $(1-x/N)^N$ must converge to $e^{-x}$. \n",
    "\n",
    "where $ \\mathcal{O}[(x/N)^2]$ is a short-hand for \"terms of second order and higher.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color='darkblue'>\"Poisson\" probability distribution</font>\n",
    "\n",
    "We thus have in the limit $N\\rightarrow\\infty$, while $\\lambda=\\rm const$\n",
    "\n",
    "$$p(n) = \\frac{\\lambda^n}{n!}\\, e^{-\\lambda},$$\n",
    "\n",
    "although this is a limiting case of binomial distribution, it was first discovered independently of it and is called *Poisson distribution* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "\n",
    "The distribution is named after Siméon Denis Poisson - a french mathematician who (re-)discovered it while studying statistics of crime in. different parts of Paris, although the first person who discovered it was actually another French mathematician, [Abraham de Moivre](https://en.wikipedia.org/wiki/Abraham_de_Moivre). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <font color='darkblue'>Abraham de Moivre (1667 – 1754), French mathematician</font>\n",
    "\n",
    "First to derive what is now called Poisson distribution for probability of discrete events occuring at a constant mean rate to occur in a given time interval. \n",
    "\n",
    "<center>\n",
    "<img width=400 src=\"https://upload.wikimedia.org/wikipedia/commons/1/1b/Abraham_de_moivre.jpg\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <font color='darkblue'>Attributed to  Siméon Denis Poisson (1781–1840), French mathematician</font>\n",
    "\n",
    "who rediscovered \"Poisson\" distribution in the 1830s. \n",
    "<center>\n",
    "<img width=400 src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Sim%C3%A9onDenisPoisson.jpg/338px-Sim%C3%A9onDenisPoisson.jpg\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_Poisson distribution plays a very important role in astronomy research_** and is used widely. We will discuss why next. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
